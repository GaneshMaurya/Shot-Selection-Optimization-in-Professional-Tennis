{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:41:10.343388Z","iopub.execute_input":"2025-05-07T05:41:10.343847Z","iopub.status.idle":"2025-05-07T05:41:15.337060Z","shell.execute_reply.started":"2025-05-07T05:41:10.343799Z","shell.execute_reply":"2025-05-07T05:41:15.335800Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom datetime import datetime\nimport pickle\nimport logging\nimport warnings\nimport gdown\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nwarnings.filterwarnings('ignore')\n\n# Setup logging\nlogging.basicConfig(filename='training_log_extended.txt', level=logging.INFO, \n                    format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger()\n\ndef log_and_print(message):\n    logger.info(message)\n    print(message)\n\n# Directory structure setup\nBASE_OUTPUT_DIR = 'model_outputs'\nMODEL_TYPES = ['xgboost']\nfor model_type in MODEL_TYPES:\n    os.makedirs(os.path.join(BASE_OUTPUT_DIR, model_type), exist_ok=True)\n\n# Load and preprocess data\ndef load_data(file_path):\n    log_and_print(\"Loading dataset...\")\n    try:\n        df = pd.read_csv(file_path)\n        log_and_print(f\"Dataset loaded with {len(df)} rows and {len(df.columns)} columns\")\n        return df\n    except Exception as e:\n        log_and_print(f\"Error loading data: {str(e)}\")\n        raise\n\ndef preprocess_data(df):\n    try:\n        # Standardize outcome labels\n        outcome_mapping = {\n            'Winner': 'Winner', 'Forced Error': 'Forced Error', 'Unforced Error': 'Unforced Error',\n            'Ace': 'Winner', 'Double Fault': 'Unforced Error'\n        }\n        df['outcome'] = df['outcome'].map(outcome_mapping)\n        df = df.dropna(subset=['outcome'])\n        log_and_print(f\"After cleaning, dataset has {len(df)} rows\")\n\n        # Select features\n        feature_columns = [\n            'serve_type', 'serve_direction', 'serve_depth', 'is_second_serve',\n            'rally_length', 'shot_1_type', 'shot_1_direction', 'shot_1_depth',\n            'shot_2_type', 'shot_2_direction', 'shot_2_depth',\n            'shot_3_type', 'shot_3_direction', 'shot_3_depth',\n            'shot_4_type', 'shot_4_direction', 'shot_4_depth',\n            'shot_5_type', 'shot_5_direction', 'shot_5_depth',\n            'last_shot_type', 'last_shot_direction', 'last_shot_depth'\n        ]\n        df_features = df[feature_columns].copy()\n        df_target = df['outcome']\n\n        # Handle missing values\n        for col in df_features.columns:\n            if df_features[col].dtype == 'object':\n                df_features[col] = df_features[col].fillna('None')\n            else:\n                df_features[col] = df_features[col].fillna(0)\n\n        # Convert categorical columns to strings\n        categorical_columns = [col for col in df_features.columns if df_features[col].dtype == 'object']\n        for col in categorical_columns:\n            df_features[col] = df_features[col].astype(str)\n        \n        # Encode categorical features\n        encoders = {}\n        for col in categorical_columns:\n            encoders[col] = LabelEncoder()\n            df_features[col] = encoders[col].fit_transform(df_features[col])\n\n        # Encode target\n        target_encoder = LabelEncoder()\n        y = target_encoder.fit_transform(df_target)\n        log_and_print(f\"Class distribution: {dict(zip(target_encoder.classes_, np.bincount(y)))}\")\n\n        return df_features, y, categorical_columns, encoders, target_encoder\n    except Exception as e:\n        log_and_print(f\"Error in preprocessing: {str(e)}\")\n        raise\n\n# Evaluation function for XGBoost\ndef evaluate_model(model, X_test, y_test, target_encoder, model_type):\n    try:\n        # Prepare test data\n        X_test_np = np.hstack([X_test[cat].values.reshape(-1, 1) for cat in X_test.columns])\n        \n        # Predictions\n        y_true = y_test\n        y_pred = model.predict(X_test_np)\n        y_scores = model.predict_proba(X_test_np)\n\n        y_true_bin = np.eye(len(target_encoder.classes_))[y_true]\n\n        # Classification report\n        report = classification_report(y_true, y_pred, target_names=target_encoder.classes_, output_dict=True)\n        log_and_print(f\"\\n[{model_type}] Classification Report:\")\n        log_and_print(classification_report(y_true, y_pred, target_names=target_encoder.classes_))\n\n        # Confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_encoder.classes_, yticklabels=target_encoder.classes_)\n        plt.title(f'Confusion Matrix - {model_type}')\n        plt.savefig(f'{BASE_OUTPUT_DIR}/{model_type}/confusion_matrix.png')\n        plt.close()\n\n        # Precision-Recall curves\n        plt.figure(figsize=(10, 8))\n        for i, class_name in enumerate(target_encoder.classes_):\n            precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_scores[:, i])\n            plt.plot(recall, precision, label=f'{class_name} (AP={np.mean(precision):.2f})')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.title(f'Precision-Recall Curve - {model_type}')\n        plt.legend()\n        plt.savefig(f'{BASE_OUTPUT_DIR}/{model_type}/precision_recall_curve.png')\n        plt.close()\n\n        # ROC curves\n        plt.figure(figsize=(10, 8))\n        for i, class_name in enumerate(target_encoder.classes_):\n            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n            auc_score = roc_auc_score(y_true_bin[:, i], y_scores[:, i])\n            plt.plot(fpr, tpr, label=f'{class_name} (AUC={auc_score:.2f})')\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve - {model_type}')\n        plt.legend()\n        plt.savefig(f'{BASE_OUTPUT_DIR}/{model_type}/roc_curve.png')\n        plt.close()\n\n        return report, cm, y_true, y_pred, y_scores\n    except Exception as e:\n        log_and_print(f\"Error in evaluation {model_type}: {str(e)}\")\n        raise\n\n# Precision-Recall imbalance analysis\ndef analyze_precision_recall(y_true, y_pred, y_scores, target_encoder, model_type):\n    try:\n        y_true_bin = np.eye(len(target_encoder.classes_))[y_true]\n        \n        # Per-class precision-recall analysis\n        analysis = {}\n        for i, class_name in enumerate(target_encoder.classes_):\n            precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_scores[:, i])\n            analysis[class_name] = {\n                'precision': np.mean(precision),\n                'recall': np.mean(recall),\n                'class_freq': np.sum(y_true_bin[:, i]) / len(y_true)\n            }\n        \n        # Visualize precision-recall differences\n        plt.figure(figsize=(10, 6))\n        classes = list(analysis.keys())\n        precisions = [analysis[c]['precision'] for c in classes]\n        recalls = [analysis[c]['recall'] for c in classes]\n        x = np.arange(len(classes))\n        width = 0.35\n        \n        plt.bar(x - width/2, precisions, width, label='Precision')\n        plt.bar(x + width/2, recalls, width, label='Recall')\n        plt.xticks(x, classes)\n        plt.ylabel('Score')\n        plt.title(f'Precision vs Recall by Class - {model_type}')\n        plt.legend()\n        plt.savefig(f'{BASE_OUTPUT_DIR}/{model_type}/precision_recall_comparison.png')\n        plt.close()\n        \n        # Log analysis\n        log_and_print(f\"\\n[{model_type}] Precision-Recall Analysis:\")\n        for class_name, metrics in analysis.items():\n            log_and_print(f\"{class_name}: Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, Class Freq={metrics['class_freq']:.4f}\")\n\n        return analysis\n    except Exception as e:\n        log_and_print(f\"Error in precision-recall analysis: {str(e)}\")\n        raise\n\n# XGBoost implementation with hyperparameter tuning\ndef train_xgboost(X_train, y_train, X_test, y_test, categorical_columns, target_encoder):\n    try:\n        X_train_np = np.hstack([X_train[cat].values.reshape(-1, 1) for cat in X_train.columns])\n        X_test_np = np.hstack([X_test[cat].values.reshape(-1, 1) for cat in X_test.columns])\n        \n        # Hyperparameter tuning\n        param_dist = {\n            'max_depth': [3, 5, 7],\n            'learning_rate': [0.01, 0.1, 0.3],\n            'n_estimators': [100, 200, 300],\n            'subsample': [0.7, 0.8, 0.9],\n            'colsample_bytree': [0.7, 0.8, 0.9]\n        }\n        \n        xgb = XGBClassifier(random_state=42)\n        search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=20, cv=3, scoring='f1_weighted', n_jobs=-1)\n        search.fit(X_train_np, y_train)\n        \n        best_model = search.best_estimator_\n        log_and_print(f\"Best XGBoost parameters: {search.best_params_}\")\n        \n        # Feature importance\n        feature_names = X_train.columns\n        importance = best_model.feature_importances_\n        plt.figure(figsize=(12, 6))\n        sorted_idx = np.argsort(importance)[::-1]\n        plt.bar(range(len(importance)), importance[sorted_idx])\n        plt.xticks(range(len(importance)), feature_names[sorted_idx], rotation=45)\n        plt.title('XGBoost Feature Importance')\n        plt.tight_layout()\n        plt.savefig(f'{BASE_OUTPUT_DIR}/xgboost/feature_importance.png')\n        plt.close()\n        \n        # Log feature importance analysis\n        log_and_print(\"\\nTop 5 important features:\")\n        for idx in sorted_idx[:5]:\n            log_and_print(f\"{feature_names[idx]}: {importance[idx]:.4f}\")\n        \n        return best_model\n    except Exception as e:\n        log_and_print(f\"Error in XGBoost training: {str(e)}\")\n        raise\n\n# Main execution\ndef main():\n    start_time = datetime.now()\n    CONFIG = {\n        'log_metrics_file': '/kaggle/working/metrics.csv',\n        'gdrive_file_id': '16IH03soaKK15gvOO4t84ohCP-n2abCYV',\n        'csv_file_name': 'dataset_subset.csv',\n    }\n\n    try:\n        # Load and preprocess data\n        file_id = CONFIG['gdrive_file_id']\n        output_path = os.path.join('/kaggle/working', CONFIG['csv_file_name'])\n        gdown.download(f'https://drive.google.com/uc?id={file_id}', output_path, quiet=False)\n        df = load_data(output_path)\n        X, y, categorical_columns, encoders, target_encoder = preprocess_data(df)\n\n        # Split data\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n        log_and_print(f\"Training set: {len(X_train)} samples, Test set: {len(X_test)} samples\")\n\n        # Save testing dataset as CSV\n        test_df = X_test.copy()\n        test_df['outcome'] = target_encoder.inverse_transform(y_test)\n        test_csv_path = os.path.join(BASE_OUTPUT_DIR, 'test_dataset.csv')\n        test_df.to_csv(test_csv_path, index=False)\n        log_and_print(f\"Testing dataset saved to {test_csv_path}\")\n\n        # Train and evaluate XGBoost\n        log_and_print(\"\\nTraining XGBoost model...\")\n        xgb_model = train_xgboost(X_train, y_train, X_test, y_test, categorical_columns, target_encoder)\n        report, cm, y_true, y_pred, y_scores = evaluate_model(xgb_model, X_test, y_test, target_encoder, 'xgboost')\n        pr_analysis = analyze_precision_recall(y_true, y_pred, y_scores, target_encoder, 'xgboost')\n        results = {\n            'xgboost': {\n                'report': report,\n                'cm': cm,\n                'pr_analysis': pr_analysis\n            }\n        }\n\n        # Save artifacts\n        output_dir = f'{BASE_OUTPUT_DIR}/xgboost'\n        with open(os.path.join(output_dir, 'results.pkl'), 'wb') as f: \n            pickle.dump(results['xgboost'], f)\n        with open(os.path.join(BASE_OUTPUT_DIR, 'target_encoder.pkl'), 'wb') as f:\n            pickle.dump(target_encoder, f)\n        with open(os.path.join(BASE_OUTPUT_DIR, 'feature_encoders.pkl'), 'wb') as f:\n            pickle.dump(encoders, f)\n        with open(os.path.join(BASE_OUTPUT_DIR, 'feature_columns.pkl'), 'wb') as f:\n            pickle.dump(X.columns.tolist(), f)\n\n        log_and_print(f\"\\nTotal execution time: {datetime.now() - start_time}\")\n        log_and_print(f\"Artifacts saved in {BASE_OUTPUT_DIR}/\")\n\n    except Exception as e:\n        log_and_print(f\"Error in main execution: {str(e)}\")\n        raise\n\nmain()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:48:55.899257Z","iopub.execute_input":"2025-05-07T05:48:55.899581Z","iopub.status.idle":"2025-05-07T06:13:13.298974Z","shell.execute_reply.started":"2025-05-07T05:48:55.899557Z","shell.execute_reply":"2025-05-07T06:13:13.298101Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=16IH03soaKK15gvOO4t84ohCP-n2abCYV\nFrom (redirected): https://drive.google.com/uc?id=16IH03soaKK15gvOO4t84ohCP-n2abCYV&confirm=t&uuid=1be45db0-55e3-44e4-b737-07eb6efae209\nTo: /kaggle/working/dataset_subset.csv\n100%|██████████| 143M/143M [00:01<00:00, 120MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Loading dataset...\nDataset loaded with 991359 rows and 41 columns\nAfter cleaning, dataset has 960585 rows\nClass distribution: {'Forced Error': 308713, 'Unforced Error': 338515, 'Winner': 313357}\nTraining set: 768468 samples, Test set: 192117 samples\nTesting dataset saved to model_outputs/test_dataset.csv\n\nTraining XGBoost model...\nBest XGBoost parameters: {'subsample': 0.8, 'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n\nTop 5 important features:\nis_second_serve: 0.2752\nlast_shot_depth: 0.1409\nlast_shot_type: 0.1064\nlast_shot_direction: 0.0842\nshot_2_direction: 0.0802\n\n[xgboost] Classification Report:\n                precision    recall  f1-score   support\n\n  Forced Error       0.84      0.72      0.77     61743\nUnforced Error       0.65      0.79      0.71     67703\n        Winner       0.78      0.72      0.75     62671\n\n      accuracy                           0.74    192117\n     macro avg       0.76      0.74      0.74    192117\n  weighted avg       0.75      0.74      0.74    192117\n\n\n[xgboost] Precision-Recall Analysis:\nForced Error: Precision=0.6361, Recall=0.8405, Class Freq=0.3214\nUnforced Error: Precision=0.6523, Recall=0.7238, Class Freq=0.3524\nWinner: Precision=0.6481, Recall=0.8008, Class Freq=0.3262\n\nTotal execution time: 0:24:14.823374\nArtifacts saved in model_outputs/\n","output_type":"stream"}],"execution_count":3}]}